import inspect
import os
import pathlib
import sys
import typing

import numpy as np
import pandas as pd
import psutil  # type: ignore
from IPython import get_ipython
from numpy.typing import NDArray


def export(function):
    module_globals = inspect.stack()[1][0].f_globals
    if "__all__" not in module_globals:
        module_globals["__all__"] = []

    module_globals["__all__"].append(function.__name__)
    # print(function.__name__, module_globals["__name__"], module_globals["__all__"])

    return function


def load_slope_values(path: str) -> tuple[int, NDArray]:
    data = np.load(path)

    return data[0], data[1:]


def get_memory() -> float:
    """Return memory usage in MB"""
    process = psutil.Process(os.getpid())
    memory_usage = process.memory_info().rss  # in bytes
    return memory_usage / (1024 ** 2)


def is_notebook() -> bool:
    try:
        # Check if the environment is an IPython shell (which includes Jupyter)
        if 'ipykernel' in sys.modules or 'IPython' in sys.modules:
            if get_ipython().__class__.__name__ == 'ZMQInteractiveShell':
                # We're in a Jupyter notebook
                return True
        return False
    except NameError:
        return False  # If 'IPython' is not available, we're not in a notebook


def get_hist(sample: typing.Sequence, bins: int | typing.Iterable | None = None, **kwargs) -> tuple[
    NDArray[np.float64], [np.float64]]:
    edges = np.array(range(
        np.floor(sample).min().astype(int),
        np.ceil(sample).max().astype(int) + 1)) - 0.5

    default = {
        "density": True,
    }
    default.update(kwargs)

    bins, edges = np.histogram(sample, bins=bins or edges, **default)

    return 0.5 * (edges[1:] + edges[:-1]), bins


def get_system_params_from_name(name: str) -> dict[str, any]:
    """

    Get the system parameters from the folder name generated by SandpileND.run_multiple_samples
    function.

    :param name: name of the folder
    :return: Dictionary of the system parameters
    """

    values = name.split("_")

    result = dict()
    result["dimension"] = int(values[0][1:])
    result["linear_grid_size"] = int(values[1][1:])
    result["critical_slope"] = int(values[2][1:])

    if values[3] == "op":
        result["boundary_condition"] = "open"
    elif values[3] == "cl":
        result["boundary_condition"] = "closed"
    else:
        raise ValueError(f"unknown boundary condition {values[3]}")

    if values[4] == "co":
        result["perturbation"] = "conservative"
    elif values[4] == "nco":
        result["perturbation"] = "nonconservative"
    else:
        raise ValueError(f"unknown perturbation {values[4]}")

    return result

def get_short_params(dct: dict[str, any]) -> dict[str, any]:
    val = dct["boundary_condition"]
    dct["boundary_condition"] = "op" if val == "open" else "cl"

    val = dct["perturbation"]
    dct["perturbation"] = "co" if val == "conservative" else "nco"

    return dct


def load_combine_avalanche_data_samples(data_dir: str | pathlib.Path) -> pd.DataFrame:
    if isinstance(data_dir, str):
        data_dir = pathlib.Path(data_dir)
    elif not isinstance(data_dir, pathlib.Path):
        raise TypeError("data_dir must be pathlib.Path or str")

    df = pd.DataFrame({})
    for file in data_dir.glob("*.avalanche.csv"):
        dfn = pd.read_csv(file)
        df = pd.concat([df, dfn], axis=0)

    return df.reset_index(drop=True)
